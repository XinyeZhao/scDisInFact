{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Iterable, List\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import scanpy as sc\n",
    "\n",
    "from model import Encoder, Decoder, gene_act\n",
    "from loss_function import MMD_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "path_mtx = r\"./data/mtx_0.mtx\"\n",
    "data_test = sc.read_mtx(path_mtx)\n",
    "mtx_data = np.array(data_test.X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27943, 238)\n"
     ]
    }
   ],
   "source": [
    "print(mtx_data.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238\n",
      "(238, 27943)\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000021B8112B4C0>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "all_data = mtx_data\n",
    "random.seed(214)\n",
    "m = len(all_data)\n",
    "print(m)\n",
    "\n",
    "train_data, test_data = random_split(dataset=all_data, lengths=[int(m - m * 0.2), int(m * 0.2) + 1])\n",
    "\n",
    "print((train_data.dataset.shape))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 27943])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = Encoder(features=[all_data.shape[1], 1024, 256, 64, 16])\n",
    "decoder = Decoder(features=[all_data.shape[1], 1024, 256, 64, 16][::-1])\n",
    "\n",
    "\n",
    "loss_fn = MMD_LOSS()\n",
    "\n",
    "# Define Optimizer\n",
    "lr = 0.001\n",
    "\n",
    "#Random seed\n",
    "torch.manual_seed(0)\n",
    "param_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(param_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "def add_noise(inputs, noise_factor=0.3):\n",
    "    noisy = inputs + torch.randn_like(inputs) * noise_factor\n",
    "    noisy = torch.clip(noisy, 0., 1.)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# ls = MMD_LOSS()\n",
    "ls = nn.MSELoss()\n",
    "# ls.forward()\n",
    "# print(ls([1,2,3], [1,2,3]))\n",
    "a = torch.zeros([2, 4])\n",
    "b = torch.ones([2,4])\n",
    "print(a, b)\n",
    "# ls.forward(a, b)\n",
    "print(ls.forward(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_epoch(encoder, decoder, dataloader, loss_fn, optimizer, noise_factor=0.3):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    for sc_data_batch in dataloader:\n",
    "        # _\n",
    "        sc_data_noisy = add_noise(sc_data_batch, noise_factor)\n",
    "        # Encode\n",
    "        encoded_data = encoder(sc_data_noisy)\n",
    "        # Decode\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, sc_data_noisy)\n",
    "        # Backword \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print\n",
    "        # print('\\t partial train loss : %f' %(loss.data))\n",
    "        train_loss.append(loss.detach().numpy())\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing func\n",
    "def test_epoch(encoder, decoder, dataloader, loss_fn, noise_factor=0.3):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # Don't track gradients\n",
    "        # conc_out = []\n",
    "        # conc_label = []\n",
    "        for sc_data_batch in dataloader:\n",
    "            sc_data_noisy = add_noise(sc_data_batch, noise_factor)\n",
    "            # Encode\n",
    "            encoded_data = encoder(sc_data_noisy)\n",
    "            # Decode\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the output list to the original image\n",
    "            # conc_out.append(decoded_data)\n",
    "            # conc_label.append(sc_data_batch)\n",
    "            # Create single tensor with all values\n",
    "            # conc_out = torch.cat(conc_out)\n",
    "            # conc_label = torch.cat(conc_label)\n",
    "            # Evaluate global loss\n",
    "            val_loss = loss_fn(decoded_data, sc_data_noisy)\n",
    "    return val_loss / len(dataloader.dataset)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_ae_outputs(encoder,decoder,n=5):\n",
    "#     plt.figure(figsize=(10,4.5))\n",
    "#     for i in range(n):\n",
    "#       ax = plt.subplot(2,n,i+1)\n",
    "#       img = test_dataset[i][0].unsqueeze(0)\n",
    "#       encoder.eval()\n",
    "#       decoder.eval()\n",
    "#       with torch.no_grad():\n",
    "#          rec_img  = decoder(encoder(img))\n",
    "#       plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "#       ax.get_xaxis().set_visible(False)\n",
    "#       ax.get_yaxis().set_visible(False)  \n",
    "#       if i == n//2:\n",
    "#         ax.set_title('Original images')\n",
    "#       ax = plt.subplot(2, n, i + 1 + n)\n",
    "#       plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "#       ax.get_xaxis().set_visible(False)\n",
    "#       ax.get_yaxis().set_visible(False)  \n",
    "#       if i == n//2:\n",
    "#          ax.set_title('Reconstructed images')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/50 \t train loss 1.274095058441162 \t val loss 0.2253832221031189\n",
      "\n",
      " EPOCH 2/50 \t train loss 1.0065284967422485 \t val loss 0.21919041872024536\n",
      "\n",
      " EPOCH 3/50 \t train loss 0.8679742813110352 \t val loss 0.21091298758983612\n",
      "\n",
      " EPOCH 4/50 \t train loss 0.8557989001274109 \t val loss 0.19935517013072968\n",
      "\n",
      " EPOCH 5/50 \t train loss 0.8024044036865234 \t val loss 0.1872086375951767\n",
      "\n",
      " EPOCH 6/50 \t train loss 0.7701113224029541 \t val loss 0.16937290132045746\n",
      "\n",
      " EPOCH 7/50 \t train loss 0.7704030871391296 \t val loss 0.1525258719921112\n",
      "\n",
      " EPOCH 8/50 \t train loss 0.777195155620575 \t val loss 0.1297452598810196\n",
      "\n",
      " EPOCH 9/50 \t train loss 0.7641347050666809 \t val loss 0.11660504341125488\n",
      "\n",
      " EPOCH 10/50 \t train loss 0.7740700840950012 \t val loss 0.11759323626756668\n",
      "\n",
      " EPOCH 11/50 \t train loss 0.7543278336524963 \t val loss 0.12235695123672485\n",
      "\n",
      " EPOCH 12/50 \t train loss 0.730754554271698 \t val loss 0.11142468452453613\n",
      "\n",
      " EPOCH 13/50 \t train loss 0.7407973408699036 \t val loss 0.10077989846467972\n",
      "\n",
      " EPOCH 14/50 \t train loss 0.7401585578918457 \t val loss 0.09037915617227554\n",
      "\n",
      " EPOCH 15/50 \t train loss 0.7426852583885193 \t val loss 0.08376633375883102\n",
      "\n",
      " EPOCH 16/50 \t train loss 0.7524582743644714 \t val loss 0.07848236709833145\n",
      "\n",
      " EPOCH 17/50 \t train loss 0.764300525188446 \t val loss 0.07463247328996658\n",
      "\n",
      " EPOCH 18/50 \t train loss 0.742455005645752 \t val loss 0.07502405345439911\n",
      "\n",
      " EPOCH 19/50 \t train loss 0.7212557792663574 \t val loss 0.07187669724225998\n",
      "\n",
      " EPOCH 20/50 \t train loss 0.7027695178985596 \t val loss 0.07324054837226868\n",
      "\n",
      " EPOCH 21/50 \t train loss 0.7277159690856934 \t val loss 0.06923624873161316\n",
      "\n",
      " EPOCH 22/50 \t train loss 0.7429519295692444 \t val loss 0.07000149041414261\n",
      "\n",
      " EPOCH 23/50 \t train loss 0.7506253719329834 \t val loss 0.07172203809022903\n",
      "\n",
      " EPOCH 24/50 \t train loss 0.7273200154304504 \t val loss 0.07545163482427597\n",
      "\n",
      " EPOCH 25/50 \t train loss 0.7136028409004211 \t val loss 0.07709161192178726\n",
      "\n",
      " EPOCH 26/50 \t train loss 0.7093127369880676 \t val loss 0.07703489810228348\n",
      "\n",
      " EPOCH 27/50 \t train loss 0.7159091830253601 \t val loss 0.07408744096755981\n",
      "\n",
      " EPOCH 28/50 \t train loss 0.729545533657074 \t val loss 0.07336530089378357\n",
      "\n",
      " EPOCH 29/50 \t train loss 0.7148000597953796 \t val loss 0.07177559286355972\n",
      "\n",
      " EPOCH 30/50 \t train loss 0.7141005992889404 \t val loss 0.07047533243894577\n",
      "\n",
      " EPOCH 31/50 \t train loss 0.709256649017334 \t val loss 0.07760027796030045\n",
      "\n",
      " EPOCH 32/50 \t train loss 0.7141642570495605 \t val loss 0.08034586161375046\n",
      "\n",
      " EPOCH 33/50 \t train loss 0.7096211314201355 \t val loss 0.08302721381187439\n",
      "\n",
      " EPOCH 34/50 \t train loss 0.7010805010795593 \t val loss 0.08356249332427979\n",
      "\n",
      " EPOCH 35/50 \t train loss 0.7280883193016052 \t val loss 0.07975111156702042\n",
      "\n",
      " EPOCH 36/50 \t train loss 0.7251644134521484 \t val loss 0.07445337623357773\n",
      "\n",
      " EPOCH 37/50 \t train loss 0.7034865021705627 \t val loss 0.06311611086130142\n",
      "\n",
      " EPOCH 38/50 \t train loss 0.700458824634552 \t val loss 0.05704580619931221\n",
      "\n",
      " EPOCH 39/50 \t train loss 0.709000289440155 \t val loss 0.06384079903364182\n",
      "\n",
      " EPOCH 40/50 \t train loss 0.7142901420593262 \t val loss 0.06737685203552246\n",
      "\n",
      " EPOCH 41/50 \t train loss 0.7207057476043701 \t val loss 0.07445625215768814\n",
      "\n",
      " EPOCH 42/50 \t train loss 0.7202355861663818 \t val loss 0.07530608773231506\n",
      "\n",
      " EPOCH 43/50 \t train loss 0.7009127140045166 \t val loss 0.06911938637495041\n",
      "\n",
      " EPOCH 44/50 \t train loss 0.701210081577301 \t val loss 0.06557541340589523\n",
      "\n",
      " EPOCH 45/50 \t train loss 0.6996309161186218 \t val loss 0.06791902333498001\n",
      "\n",
      " EPOCH 46/50 \t train loss 0.7026121020317078 \t val loss 0.07270307093858719\n",
      "\n",
      " EPOCH 47/50 \t train loss 0.6933519840240479 \t val loss 0.0768500417470932\n",
      "\n",
      " EPOCH 48/50 \t train loss 0.6922647356987 \t val loss 0.08278078585863113\n",
      "\n",
      " EPOCH 49/50 \t train loss 0.6900672316551208 \t val loss 0.08837300539016724\n",
      "\n",
      " EPOCH 50/50 \t train loss 0.6974384784698486 \t val loss 0.09131868928670883\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss =train_epoch(encoder,decoder, train_loader,loss_fn,optim)\n",
    "   test_loss = test_epoch(encoder,decoder,test_loader,loss_fn)\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,test_loss))\n",
    "   diz_loss['train_loss'].append(train_loss)\n",
    "   diz_loss['val_loss'].append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21b81889d00>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkk0lEQVR4nO3deXxc1X338c9Po9G+L5ZsyfuKbRaDYvY9EBMolKxQkqZtKG0KKe2TPG3ShyYpTZp0JW1CmhLgSZNXC6FJICaBAGHfbYFZbGPL8m55027tmuX0jzPCsrEtYY00nqvv+/W6r5l752rmd6XRd+6ce+655pxDRETSX0aqCxARkeRQoIuIBIQCXUQkIBToIiIBoUAXEQmIzFS9cEVFhZs1a1aqXl5EJC299tprLc65yiM9lrJAnzVrFvX19al6eRGRtGRm24/2mJpcREQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQmItAv0DXsP8K1HN9DZF0l1KSIiJ5S0C/SdbX18/9nNbG3pSXUpIiInlLQL9NkVeQBsU6CLiBwi7QK9tjQPM9jWqkAXERku7QI9JxxiWnGu9tBFRA6TdoEOMKsij62tvakuQ0TkhJKegV6ez3Y1uYiIHCJtA72jN0JH72CqSxEROWGkZ6BX5AOwTc0uIiLvSstAV9dFEZH3GjHQzexeM9tvZmuP8vgNZvaWmb1tZi+Z2anJL/NQQ10XdXKRiMhBo9lD/yGw4hiPbwUudM6dDPwtcFcS6jqmoa6LOjAqInLQiNcUdc49Z2azjvH4S8NmXwFqk1DXiNR1UUTkUMluQ/8s8OjRHjSzm8ys3szqm5ubx/RC6rooInKopAW6mV2MD/S/PNo6zrm7nHN1zrm6ysrKMb2eui6KiBwqKYFuZqcAdwPXOOdak/GcIxnquqgDoyIi3pgD3cxmAD8HPu2caxh7SaMz1HVxu9rRRUSAURwUNbP7gIuACjPbBXwVCAM4574PfAUoB75nZgBR51zdeBU8RF0XRUQONZpeLteP8PiNwI1Jq2iU1HVRRORQaXmm6BB1XRQROSi9A708X6f/i4gkpHWgz67Ip7NPXRdFRCDNA31mubouiogMSetAV9dFEZGD0jrQ1XVRROSgtA70dy8Yra6LIiLpHejguy7qykUiIkEIdHVdFBEBAhDo6rooIuKlfaCr66KIiJf2gf7uBaN1YFREJrm0D/ShrovbWnRgVEQmt7QPdHVdFBHx0j7QwR8YVddFEZnsAhHoM8vz1HVRRCa9QAT6UNfF9h51XRSRySsQgT7UdVHt6CIymQUi0NV1UUQkIIGurosiIgEJdHVdFBEJSKBDouuierqIyCQWmECfWa5hdEVkcgtMoKvroohMdiMGupnda2b7zWztUR43M/s3M2s0s7fM7PTklzkydV0UkcluNHvoPwRWHOPxK4D5iekm4N/HXtb7N9R1sXF/dypeXkQk5UYMdOfcc0DbMVa5BviR814BSsxsarIKHK3ZFQWU5IV5eUvrRL+0iMgJIRlt6DXAzmHzuxLL3sPMbjKzejOrb25uTsJLHxTKMM6bV8Hzm1pwziX1uUVE0sGEHhR1zt3lnKtzztVVVlYm/fkvWFBJc9cAG/Z2Jf25RUROdMkI9CZg+rD52sSyCXf+/AoAnmtI7t6/iEg6SEagrwR+N9Hb5Syg0zm3JwnP+75NLc5lQVUBz21SoIvI5JM50gpmdh9wEVBhZruArwJhAOfc94FHgA8DjUAv8PvjVexoXDC/kh+9vJ2+wRi5WaFUliIiMqFGDHTn3PUjPO6Am5NW0Ridv6CSu1/YyitbW7l44ZRUlyMiMmECc6bokDNnl5GdmaF2dBGZdAIX6DnhEMtnl/H8ppZUlyIiMqECF+jg29Eb93ezu6Mv1aWIiEyYYAb6At/HXc0uIjKZBDLQF1QVUFWUrWYXEZlUAhnoZsb58yt5obGFWFzDAIjI5BDIQAff7NLZF+HNXR2pLkVEZEIENtDPm1eBGTzfoGYXEZkcAhvoZflZnFxTrGEARGTSCGygg++++MbODjr7IqkuRURk3AU70BdUEos7Xt6sZhcRCb5AB/qyGSUUZGfyrNrRRWQSCHSgh0MZnD23nOcamnUVIxEJvEAHOsAF8yto6uhja0tPqksRERlXwQ/0xDAAP3p5O+09gymuRkRk/Iw4Hnq6m1mez3nzKvjhS9v48SvbOXN2GSuWVnP54mqqi3NSXZ6ISNJYqtqW6+rqXH19/YS8lnOOt5s6+fXavTy2bi+bm33zy2nTS7jx/Nlcdcq0CalDRGSszOw151zdkR4L/B46+LFdTqkt4ZTaEv5ixSIa93fx2Lp9PLSmiVvvf4OpxbmcMbM01WWKiIxJ4NvQj2TelEJuvngeP/uTc5hanMOf/WQNXf06+UhE0tukDPQhRTlhvv3J02hq7+Mrv1iX6nJERMZkUgc6QN2sMv700vk8uKaJX7zRlOpyRESO26QPdIBbLp5H3cxSbntwLTvbelNdjojIcVGgA5mhDO745GkA3Hr/GqKxeGoLEhE5DqMKdDNbYWYbzazRzL50hMdnmNnTZrbGzN4ysw8nv9TxNb0sj69fu5TXd3TwnacaU12OiMj7NmKgm1kIuBO4AlgMXG9miw9b7TbgAefcMuA64HvJLnQiXHNaDR9ZVsN3ntpE/ba2VJcjIvK+jGYPfTnQ6Jzb4pwbBO4HrjlsHQcUJe4XA7uTV+LE+ptrllBbmsef3reGzc3dqS5HRGTURhPoNcDOYfO7EsuG+xrwKTPbBTwCfP5IT2RmN5lZvZnVNzefmFcSKswJ870bTmcgGufaO1/kxUYNvSsi6SFZB0WvB37onKsFPgz82Mze89zOubucc3XOubrKysokvXTyLa0p5qGbz6W6OIfP3LuK+1btSHVJIiIjGk2gNwHTh83XJpYN91ngAQDn3MtADlCRjAJTZXpZHj/73DmcO6+CL//8bb7+y/XE4hpTXUROXKMZy2U1MN/MZuOD/Drgdw5bZwdwKfBDMzsJH+gnZpvK+1CYE+aez9Tx9V+9w90vbGVbaw//et0y8rOP/mvrHYzSsK+bDXsOsGFvFw37uqgqyuHKk6dy/oIKsjNDx3zNPZ19NHcNcHJNMWaW7E0SkQAb1WiLiW6I3wZCwL3OuW+Y2e1AvXNuZaLXyw+AAvwB0r9wzj1+rOecyNEWk+HHL2/jaw+vZ2Z5HidNLcI5RzwOcedwQCQWZ1tLD9vbehn6leaGQ8yvKmB7ay+dfRGKcjL50JJqfuvUaZwzt5zMUAbtPYO8vKWVFxtbeHlzK1sSF+JYNqOEL16+kHPnpfUXHRFJsmONtjgphs9NlucamvnWoxvoj8bIMCPDIMMMMyOUAdNL81hUXcTC6kJOmlrI9NI8MjKMwWicFxtbePjN3Ty+fh/dA1HK8rOoKsphw94DOAf5WSHOnFPOOXPLyc7M4N+f2czuzn7OmlPGFy9fSN2sslRv/iG6+iM8s7GZ5zc1s7SmmOuXzyAc0nlqIuNNgX4C6Y/EeLahmYff3E177yBnzS7nnHkVnFJbfEggDkRj3L9qJ999upHmrgEuXFDJFy5fwCm1JSmrfU9nH79Zv4/H1+/jlS2tRGKO/KwQPYMx5k0p4LYrT+KihVNSVp/IZKBAT2N9gzF+9PI2vv/sZtp7I3zsjFq+fMUiyguyx/21ewej1G9r56XNvkno7aZOAGZX5HP54iouW1zFshmlPLVhP9/41Xq2tfZy0cJKbrtyMfOmFIx7fYeLxOI07OtibVMnpXlZXLa4SschJHAU6AHQ1R/he89s5gfPbaEgJ5MvX7GIj58xnYyMsQdWLO440Behsy/C7o4+XtnSystbWnljZweRmCMzwzhtegkXL5rCh5ZUMbey4D1BORiN858vbePfntxEbyTGp8+ayZ99cD4leVljru9otrb0sHprG281dfB20wHe2XOAwejBcXjOnlPO3/72EuZNKRy3GkQmmgI9QBr2dXHbg2tZta2NupmlfP3apSyqLnr38b7BGKu3tfHiZn+QtbV7kFCGkZlhhBJTOJRBdFiIdw9ED3mNDIOTa0s4e045Z88tp25m6TF79gzX2j3APz/RwP2rdlCYE+bzl8zj02fPHLF3z2j1R2I8unYP9726k1WJ4RkKszNZUlPEyTXFnFxbwtJpRby0uZV/+PUG+iIx/vD8OXz+kvnkZiWnBpFUUqAHjHOOn762i7975B26+qP8/rmzKMoJ8+LmFl7f3sFgLE44ZCybXsqM8jxicUc07ojF40Rj/n6GQVFumOJhU1FOmIrCbJbNKKEoJzymGjfsPcDfPbKB5xqamV6Wy1+uWMSVJ0897iaQhn1d3LdqBz9/vYnOvggzy/O4fvkMLltcxezy/CN+U2npHuCbj2zgZ6/voqYkl69dvYTLFleNabtG4pzDOZLyzUnkSBToAdXeM8i3Ht3AT+r9yAyLpxZx3vwKzplbzvLZZeRlpf6Ssc82NPPNR95hw94uls0o4bYrT+KMmaPvsbN+9wG+9vA6Vm1tIxwyPrSkmt9ZPoOz5pSPOjRf3dLKX/9iLQ37urlgQSU3nDmDixZWJu1bA8DGvV08uKaJh9/czYH+CFefOo1PfmD6CX0+Qf22Nv7xsY3EnaM0L8tP+VmU5oUpzc/i/PkVTC3OTXWZchgFesDtaO2lICeTsvzxa68ei1jc8bPXdvFPj29kf9cAK5ZU8/lL57FkWvFRf2YgGuO7TzXy789spiQvzE0XzOGjp9ce98HgSCzO/39xK//x7BZaewYpzg1z5SlTuXZZDWfMKD2uPerdHX2sfHM3D61pYsPeLkIZxgXzKyjODfPo2r0MROMsqi7kE3XTuXZZDaUnyN8nEovznSc38d2nG6kuymFGeR7tPRHaewdp7x0kEvOZkJ2ZwU0XzOGPL5w76ia349XRO0jDvm4a9nXRuL+b7oEoITNCIfO3GUaGGbMr8/n4GbXkhCdv85kCXU4IvYNRfvDcVu5+fgtdA1EuXTSFWy6Zx7IZpYes9/qOdv7yp2+xaX83Hzm9hr++cnHSwjASi/NCYwu/WNPEY+v20ReJUVuay1WnTGP+lAKmluQwrTiX6uKcd0PDOUdz1wAb93WxMXH274a9Xbzd1Ilz/iSw3z6thitPmUpF4gOnsy/Cw2/u5oH6nby1q5OsUAbnzCunKCdMZsgf08gMZRDOMLIyM6gqyqG2NI/pZbnUluZRnHuwySsai7Ons5+d7b3sautjV7u/qta0klymleRSU5rLtOLcUR0j2NbSw60/eYM3d3bwkdNr+Jurl1A4rHnNOUfPYIym9j7ufLqRlW/uZkphNl/80EI+dnrtmJqSBqIxdrb1saOth+2tvWxr6WHT/m427e+muWvg3fXys0IU54aJOUcscfJeLO6IxuL0DMaYUpjNn1w0l+uWz5iUwa5AlxNKZ1+EH720jXte3EpHb4Tz5lVwyyXzOLW2hH96fCP3vriV6qIc/u4jJ3PxOPZr7xmI8vj6vTy4ZjcvbGrm8KF6yvKzmFKYzd4D/XT0Rt5dXlGQzcLqAs6cXc41p01jZnn+MV/nnT0H+MnqnbzY2EIkFicSSwRUPE407uiPxOiPHHqVrKKcTKaV5NI9EGVPZ/8h4wgNZerh9ZbnZzGzPI9lM0o5fUYpp88sebfJxDnHT1bv5PZfriccyuAb1y7lqlOmjfg7en1HO7c/vJ43dnawZFoRf33VYs6aUz7iz7V0D/D69nZe39HB200dbGvpZXdnH8PjJj8rxLwpBcyvKmRB1dBtIdOKc47aTPXy5lbu+E0Dq7a2UV2Uw82XzOMTdbVJbT470SnQ5YTUMxDlv17dzl3PbaWle4CC7Ey6B6LccOYMvnTFokP2HMdbfyTGns5+9nT0sXvY7f4D/UwpymFhVQELqgtZWFWY9HMAnHN09kXY2dbn98Lbe9nZ1kdTRx+FOZlMT+y5+9s8qotzANh3oJ/dHf00dfSyu6OfXe19NO7v4q1dnQwkum9OK85h2cxSegeiPL2xmXPmlvPPnzj1fbWNO+dY+eZu/v7RDezu7OekqUVMKcymLN+3u5fl+zb3aMyxZocP8R2Ja/OGQ8ZJU4uYU5HPzPJ8ZpbnvXtbnp91XMcXnHO8tLmVO55ooH57O9OKc7jhrJkUZGcSd464O3hw2uHICYfICYfIywqRGw6Rm+XnewditPUO0t4zSFuPb25q6xmkPD+L5bPL+cDsUqYU5rzv+sabAl1OaP2RGA/U+z3Y3ztnNmfPHXkPUI5uMBpn/Z4DiT3kdtbs6KCle4AvXL6AG8+bc9zNJv2RGPe+uJXVW9to6xlMhOGh3V6nFGa/++3g9BmlLK0pHrdmEeccLzS2cMcTDby+o2PMz1eSF6Y0L4u9nf30RWIAzKnIZ/nsMpbPLmNRdRE54QyywyGyQhlkZWaQnZlBVijjmL/TnoEo7+w5wLrdB1i3u5O1TQf4yOk13Hj+nOOqU4EuMsnF4o7QOHWl7I/E6OiN4HBUFx29uWS8OOdoTzSJZRjYsHGWHDAQidE7GKM/cdsX8VN+Vqb/dpGXRXFumMzE0BuRWJx1uw+wamsrq7a2sWprGwf6o8eoAAqyMynMGZrCFGRnkp2ZQWNzN1tbet5tairPz2LxtCI+dkYt15x2+HWCRkeBLiJynOJxx4a9XWxr7WEwGmcwGmcgFmcgEmMwFqc/Eqe7P0pXf4Su/ihdA/62bzDG7Ip8lkwrZsm0IpbWFFNVlD3mD7xjBXrqOyqLiJzAMjKMxdOKWDytaOSVU0zjnYqIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCBGFehmtsLMNppZo5l96SjrfMLM1pvZOjP77+SWKSIiIxlxLBczCwF3ApcBu4DVZrbSObd+2DrzgS8D5zrn2s1s/K5KICIiRzSaPfTlQKNzbotzbhC4H7jmsHX+ELjTOdcO4Jzbn9wyRURkJKMJ9Bpg57D5XYllwy0AFpjZi2b2ipmtONITmdlNZlZvZvXNzc3HV7GIiBxRsg6KZgLzgYuA64EfmFnJ4Ss55+5yztU55+oqKyuT9NIiIgKjC/QmYPqw+drEsuF2ASudcxHn3FagAR/wIiIyQUYT6KuB+WY228yygOuAlYet8xB+7xwzq8A3wWxJXpkiIjKSEQPdORcFbgEeA94BHnDOrTOz283s6sRqjwGtZrYeeBr4v8651vEqWkRE3kvXFBURSSPHuqaozhQVEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIEYV6Ga2wsw2mlmjmX3pGOt91MycmdUlr0QRERmNEQPdzELAncAVwGLgejNbfIT1CoFbgVeTXaSIiIxsNHvoy4FG59wW59wgcD9wzRHW+1vg74H+JNYnIiKjNJpArwF2DpvflVj2LjM7HZjunPvVsZ7IzG4ys3ozq29ubn7fxYqIyNGN+aComWUA/wJ8YaR1nXN3OefqnHN1lZWVY31pEREZZjSB3gRMHzZfm1g2pBBYCjxjZtuAs4CVOjAqIjKxRhPoq4H5ZjbbzLKA64CVQw865zqdcxXOuVnOuVnAK8DVzrn6calYRESOaMRAd85FgVuAx4B3gAecc+vM7HYzu3q8CxQRkdHJHM1KzrlHgEcOW/aVo6x70djLEhGR90tnioqIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQKRfoPd1wL51EB1IdSUiIieUzFQX8L5teRr+5/fAQlA6CyoXQeWCxO1CmLIYMrNTXaWIyIRLv0CffhZ89B5o3gjNG6ClATY9DvGIfzyUBdUnQ+0HoKYOas+A0tlgltq6RUTG2agC3cxWAP8KhIC7nXPfOuzx/wPcCESBZuAPnHPbk1yrVzQVTv7YoctiEWjbCs3vQNNrsOs1eP1H8Or3/eN55TDrfFj4YZh/GeSVjUtpIiKpNGKgm1kIuBO4DNgFrDazlc659cNWWwPUOed6zexzwD8AnxyPgo8oFE40uyyAxdf4ZbGoD/hdq2Hnatj8JKx/CCwDZpwNC1bAwiugYv6ElSkiMp7MOXfsFczOBr7mnPtQYv7LAM65bx5l/WXAd51z5x7reevq6lx9ff1xFX1c4nHYvQYaHoWNj8K+tX55+Xw46SpY9FtQc7qaZkTkhGZmrznn6o702GiaXGqAncPmdwFnHmP9zwKPHqWQm4CbAGbMmDGKl06ijAzfnl57BlxyG3TsgI2/ho2/ghf/DV64A4pqYNGVcNJvwYxzIJR+hxhEZPJKamKZ2aeAOuDCIz3unLsLuAv8HnoyX/t9K5kBZ97kp942aHgMNvzSt72vugvyK+HMP4IP3Ai5pSktVURkNEYT6E3A9GHztYllhzCzDwL/D7jQOZdencTzyuC06/002AONT/pgf+rr8MK34Yzfg7NvhqJpqa5UROSoRnNi0WpgvpnNNrMs4Dpg5fAVEu3m/wFc7Zzbn/wyJ1BWPiy+Gj71U/jjF/yB01e+B98+BX5xMzQ3pLpCEZEjGjHQnXNR4BbgMeAd4AHn3Dozu93Mrk6s9o9AAfA/ZvaGma08ytOll+qT4aN3w5+u8Xvpb/8U7lwO//1J2PIsjHBAWURkIo3Yy2W8THgvl2TobobVP4DV90BvC1QthbM+Byd/XGenisiEOFYvl/QbyyWVCirh4r+CP18HV38HXNw3w9yxBJ75FvS1p7pCEZnEFOjHI5wDp/8ufO4l+PRDMG0ZPPNN+E4dvP5j3+ddRGSCKdDHwgzmXgw3/A/80fNQPg9W3gL3fBCaXk91dSIyySjQk2XqKfAHv4Zr/wM6dsIPLoGHb4We1lRXJiKThAI9mczg1Ovg86/BWX/im1++ewY8+4/QtiXV1YlIwKmXy3ja/w489lew+Sk/P20ZLP0oLLkWimtH/nnn/IHWju1+qIKeFj/eTPWpfigDEZl0jtXLRYE+ETp3wboHYe3P/ABh4Ed8nH4mxKMQG/RTdBBiAzDQDZ07fYgPdr/3+fKnwLwPwvwPwtxLNDSByCSiQD+RtG6GdT+HtT/3F+nIzPYX5QhlHbwfzoOS6X68meFTTgnseBk2PeGHA+5r98MB137AB/y8S2HqMu29iwSYAj2I4jF/MY9NT0DjE7D7DcBBbpnveTP3Uh/whdWprlREkkiBPhn0tMDmp/2ee+OT0JMYUmfKkkTAXwIzz4FwbmrrFJExUaBPNs75C3g0/saH/I6XfRt9KBtmng1zLvaX5JtyEmTlpbpakeCKx6C/E3pbh01t/qL20z9wXE851gtcSLox8wOLVZ8M5/05DPbC9pd8b5stT8Nvvjq0IpTOgqolPtynnASVJ0HZbO3Jp6NY1B9Ed3F/sD0e9YESj/pjLfmV+gAfDwPd0LbZHx9r3Zy43+ivc9zbChxhp/mczx93oB+LAn0yyMrzPWLmf9DPH9gDu1bB/g2wf72fNj4KLnbwZwqnQdkcKJsFpbN9yBfV+Db5gmo//EEQxGMQ6YVIP4f+4yUuRWgG2YUTP/haPO67q3bv83t0fe2Jafj94VMHDBwY+Xmzi/3fsLAKCqf6+yUz/d+3bA4U1epKXUcSj8OBJmjdBC2boKUhcbsJunYfum5Rjf9dLroSCqr8RerzyiGvdNj9inEpU00u4kX6/Zu1eaM/CaptK7Rv9fe79713/ZySRCBU+aYcF/cfCC7uQ9I5H4L5Ff7Nm594E+dXQFYBRPsh0nfobTzqu2QWTU0891TILhi59lgUIj3+4iSDvX4vta/d192199Db3tbEej0+yKP9o/v9ZBX4C6EM/UPmlvmx80NhyMj0UygMGWHIzIJwvv+Wk5W4DeclphzIzD14m5nt955bNsLetbD3bT/tW3vkLqsW8t1Uc0t8Dbmlh05DNVnGwboyQv5v0rMfuvZB157E72SP/73EBg8+f0bmwYCvXQ4LPgRTTx3/a+32d8K+df53sG+t/+CKRRJdeiMH72flQ+VCqFiYuDD8Ih+aY6nPOf+hOXS+R+cu/7s50AQHdvupa49/fw7JLvYXmK9YABXz/LAfZXN9kI/ztyC1ocvYDHT7N/tQAHTtORgMXXshHvFBYxk+PCzDz0d6/TDDPa0+cI9HdpHfi7SMg//Y8WG3kX7fd/9Ywvn+g6eg+uAHSlYiYLPyE0GbezAUhv9POAcDnf4ffqj9s7fVb1ekL1FHonkjFjn0W87xyCqE6qW+uaxqKRTXHAzuvDL/eDK7pcbj/u849OHdlrht3Zy4kLrzH6zzL4cFK2DOhf539n4N9voPlO79/sOke59/D+1f7z/AOrYfXDe3zP/NQ2HfjTcjnLgf9sHf3OD/JkOyi6F8buLb4xQf8PmVib3jMv936u9873Rgtw/wjh3vfX+G8/wVygqn+j3uomn+ZMCKBX4qmJKyC8or0CX1In2+J05vi987zszxUzjXT5k5PrR7mg/uEXXt8c1D3Xt9sIayDu4RD+0Nh3N8QA+F81BY5xT7AC+s8k0mEyUe93uSkV4/Dfb6sIj0+fvR/kO/lUT7/QdB+Twf4iUzT5zzCHpafLfYhl/74y8DB/y3sZoz/N5xxUIfbpULfFNNRob/wNu3zgf1vnV+amk4SnOQ+SAe+vCqPsV/mBVOPXZYOud3JFo2+nBv3uA/hHqa/QdFTwtHbLcekhGGnCIf0iUzh53rkbhfXOO/gaYosEeiQBeRsYkO+t5SDY/58x9aNh46/n84z39wDm+eyy3zB9wrF/nwLKhKTEN7zxXj014fi/odh+79/ttUVr7/gM8p9t/4hn8bS0Pq5SIiY5OZ5Ztb5lx4cFlPi9/7bt7oDw72d/j27aol/vyHwurUBGcoM3Hgd/KdVKdAF5Hjk584yD3znFRXIgknSGOdiIiMlQJdRCQgFOgiIgGhQBcRCYhRBbqZrTCzjWbWaGZfOsLj2Wb2k8Tjr5rZrKRXKiIixzRioJtZCLgTuAJYDFxvZosPW+2zQLtzbh5wB/D3yS5URESObTR76MuBRufcFufcIHA/cM1h61wD/Gfi/k+BS83SuOe+iEgaGk2g1wA7h83vSiw74jrOuSjQCZQf/kRmdpOZ1ZtZfXNz8/FVLCIiRzShJxY55+4C7gIws2Yz2z7CjxxNBdCStMLSy2Tddm335KLtPrqZR3tgNIHeBEwfNl+bWHakdXaZWSZQDLQe60mdc5WjeO0jMrP6o41lEHSTddu13ZOLtvv4jKbJZTUw38xmm1kWcB2w8rB1VgKfSdz/GPCUS9WoXyIik9SIe+jOuaiZ3QI8BoSAe51z68zsdqDeObcSuAf4sZk1Am340BcRkQk0qjZ059wjwCOHLfvKsPv9wMeTW9ox3TWBr3Wimazbru2eXLTdxyFl46GLiEhy6dR/EZGAUKCLiARE2gX6SOPKBIWZ3Wtm+81s7bBlZWb2hJltStyWprLG8WBm083saTNbb2brzOzWxPJAb7uZ5ZjZKjN7M7Hdf5NYPjsxPlJjYrykrFTXOh7MLGRma8zsl4n5wG+3mW0zs7fN7A0zq08sG9P7PK0CfZTjygTFD4EVhy37EvCkc24+8GRiPmiiwBecc4uBs4CbE3/joG/7AHCJc+5U4DRghZmdhR8X6Y7EOEnt+HGTguhW4J1h85Nluy92zp02rO/5mN7naRXojG5cmUBwzj2H7wI63PAxc/4T+O2JrGkiOOf2OOdeT9zvwv+T1xDwbXded2I2nJgccAl+fCQI4HYDmFktcCVwd2LemATbfRRjep+nW6CPZlyZIKtyzu1J3N8LVKWymPGWGIZ5GfAqk2DbE80ObwD7gSeAzUBHYnwkCO77/dvAXwDxxHw5k2O7HfC4mb1mZjcllo3pfa6LRKcp55wzs8D2OTWzAuBnwJ855w4MH7wzqNvunIsBp5lZCfAgsCi1FY0/M7sK2O+ce83MLkpxORPtPOdck5lNAZ4wsw3DHzye93m67aGPZlyZINtnZlMBErf7U1zPuDCzMD7M/8s59/PE4kmx7QDOuQ7gaeBsoCQxPhIE8/1+LnC1mW3DN6FeAvwrwd9unHNNidv9+A/w5YzxfZ5ugT6acWWCbPiYOZ8BfpHCWsZFov30HuAd59y/DHso0NtuZpWJPXPMLBe4DH/84Gn8+EgQwO12zn3ZOVfrnJuF/39+yjl3AwHfbjPLN7PCofvA5cBaxvg+T7szRc3sw/g2t6FxZb6R2orGh5ndB1yEH05zH/BV4CHgAWAGsB34hHPu8AOnac3MzgOeB97mYJvqX+Hb0QO77WZ2Cv4gWAi/o/WAc+52M5uD33MtA9YAn3LODaSu0vGTaHL5onPuqqBvd2L7HkzMZgL/7Zz7hpmVM4b3edoFuoiIHFm6NbmIiMhRKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgHxv97W5QIjo4rVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# print(diz_loss)\n",
    "x_ax = range(len(diz_loss['train_loss']))\n",
    "# print(x_ax)\n",
    "# y_tcs = np.arange(0.1, 1, 0.05)\n",
    "# ax.set_ylim([0.1, 0.4])\n",
    "# plt.yticks(y_tcs)\n",
    "plt.plot(x_ax, diz_loss['train_loss'])\n",
    "plt.plot(x_ax, diz_loss['val_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD model from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def MMD(x, y):\n",
    "    '''\n",
    "    Using gaussian kernel for MMD\n",
    "    '''\n",
    "    xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "    print(xx, xx.diag(),xx.diag().unsqueeze(0), rx)\n",
    "    dxx = rx.t() + rx - 2. * xx # Used for A in (1)\n",
    "    dyy = ry.t() + ry - 2. * yy # Used for B in (1)\n",
    "    dxy = rx.t() + ry - 2. * zz # Used for C in (1)\n",
    "    \n",
    "    XX, YY, XY = (torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device))\n",
    "    \n",
    "    # applying kernel method\n",
    "    sigmas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100, 1e3, 1e4, 1e5, 1e6]\n",
    "    for sigma in sigmas:\n",
    "        XX += torch.exp(-0.5*dxx/sigma)\n",
    "        YY += torch.exp(-0.5*dyy/sigma)\n",
    "        XY += torch.exp(-0.5*dxy/sigma)\n",
    "\n",
    "    return torch.mean(XX + YY - 2. * XY)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a52b259244b164c4849f7abc64962394aa861a8ee3a9faf3dff56f5ce380f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('scanpy_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
